@misc{https://doi.org/10.48550/arxiv.1703.07015,
  doi = {10.48550/ARXIV.1703.07015},
  url = {https://arxiv.org/abs/1703.07015},
  author = {Lai, Guokun and Chang, Wei-Cheng and Yang, Yiming and Liu, Hanxiao},
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Modeling Long- and Short-Term Temporal Patterns with Deep Neural Networks},
  publisher = {arXiv},
  year = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{https://doi.org/10.48550/arxiv.1706.03762,
  doi = {10.48550/ARXIV.1706.03762},
  url = {https://arxiv.org/abs/1706.03762},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Attention Is All You Need},
  publisher = {arXiv},
  year = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{https://doi.org/10.48550/arxiv.1907.00235,
  doi = {10.48550/ARXIV.1907.00235},
  url = {https://arxiv.org/abs/1907.00235},
  author = {Li, Shiyang and Jin, Xiaoyong and Xuan, Yao and Zhou, Xiyou and Chen, Wenhu and Wang, Yu-Xiang and Yan, Xifeng},
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Enhancing the Locality and Breaking the Memory Bottleneck of Transformer on Time Series Forecasting},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{https://doi.org/10.48550/arxiv.2012.07436,
  doi = {10.48550/ARXIV.2012.07436},
  url = {https://arxiv.org/abs/2012.07436},
  author = {Zhou, Haoyi and Zhang, Shanghang and Peng, Jieqi and Zhang, Shuai and Li, Jianxin and Xiong, Hui and Zhang, Wancai},
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Information Retrieval (cs.IR), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{https://doi.org/10.48550/arxiv.2106.13008,
  doi = {10.48550/ARXIV.2106.13008},
  url = {https://arxiv.org/abs/2106.13008},
  author = {Wu, Haixu and Xu, Jiehui and Wang, Jianmin and Long, Mingsheng},
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting},
  publisher = {arXiv},
  year = {2021},
  copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International}
}

@misc{https://doi.org/10.48550/arxiv.1607.06450,
  doi = {10.48550/ARXIV.1607.06450},
  url = {https://arxiv.org/abs/1607.06450},
  author = {Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E.},
  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Layer Normalization},
  publisher = {arXiv},
  year = {2016},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{https://doi.org/10.48550/arxiv.2201.12740,
  doi = {10.48550/ARXIV.2201.12740},
  url = {https://arxiv.org/abs/2201.12740},
  author = {Zhou, Tian and Ma, Ziqing and Wen, Qingsong and Wang, Xue and Sun, Liang and Jin, Rong},
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {FEDformer: Frequency Enhanced Decomposed Transformer for Long-term Series Forecasting},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution 4.0 International}
}


@article{6795228,
  author = {Williams, Ronald J. and Zipser, David},
  journal = {Neural Computation},
  title = {A Learning Algorithm for Continually Running Fully Recurrent Neural Networks},
  year = {1989},
  volume = {1},
  number = {2},
  pages = {270-280},
  doi = {10.1162/neco.1989.1.2.270}
}

@article{cleveland90,
  added-at = {2009-10-28T04:42:52.000+0100},
  author = {Cleveland, Robert B. and Cleveland, William S. and McRae, Jean E. and Terpenning, Irma},
  biburl = {https://www.bibsonomy.org/bibtex/24bf4893a61f6e30b2dbf7f37884295ed/jwbowers},
  citeulike-article-id = {106881},
  date-added = {2007-09-03 22:45:16 -0500},
  date-modified = {2007-09-03 22:45:16 -0500},
  interhash = {a8931b8eac108ccff1bb30b75130aac9},
  intrahash = {4bf4893a61f6e30b2dbf7f37884295ed},
  journal = {Journal of Official Statistics},
  keywords = {graphical_methods statistics},
  pages = {3--73},
  timestamp = {2009-10-28T04:43:05.000+0100},
  title = {STL: A Seasonal-Trend Decomposition Procedure Based on Loess (with Discussion)},
  volume = 6,
  year = 1990
}

@misc{https://doi.org/10.48550/arxiv.2202.07125,
  doi = {10.48550/ARXIV.2202.07125},
  url = {https://arxiv.org/abs/2202.07125},
  author = {Wen, Qingsong and Zhou, Tian and Zhang, Chaoli and Chen, Weiqi and Ma, Ziqing and Yan, Junchi and Sun, Liang},
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Signal Processing (eess.SP), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},
  title = {Transformers in Time Series: A Survey},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
